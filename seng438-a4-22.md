**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group \#: 22      | Names    |
| -------------- | --- |
| Student Names: | Topan Budiman    |
|                | Mark Ngu    |
|                | Jacob Schon    |
|                | Muhammed Shah    |

# Introduction

In this lab, we learned how to test for mutations of the SUT and how to increase the amount of mutants killed by the test suite. For both DataUtilities and Range, the objective was to increase the mutation coverage of our lab 3 test suite by 10% by updating or adding test cases.

# Analysis of 10 Mutants of the Range class 

An example of some mutants that we tested during the Range class were as the following:
1. Negated double local variable number 1 → KILLED
2. Incremented (a++) double local variable number 1 → KILLED
3. Decremented (a--) double local variable number 1 → KILLED
4. Incremented (++a) double local variable number 1 → KILLED
5. Decremented (--a) double local variable number 1 → KILLED
Originally these 5 all survived when we were testing our constraint method. We soon realized that the simplest way to fix this would be to use a range and then test values that were simply 1 above, and 1 below the numbers that we were dealing with. This effectively allowed us to kill these tests as well as similar tests that appeared in other methods. Moreover,
6. negated conditional → KILLED
7. removed conditional - replaced equality check with false → KILLED
8. removed conditional - replaced equality check with true → KILLED
9. not equal to equal → KILLED
These mutants were also originally surviving in the combine method, however as previously mentioned the most simple method for us to kill these were to create multiple tests where the conditions would have to be acknowledged as compared to our old test where they were not. Lastly, 
	3. Incremented (a++) double local variable number 3 → SURVIVED
A mutant that we were not able to kill was the incrementation of the local variable in the Range constructor, we were unable to deal with this as the incrementation would happen after the function had been called and there was no way to actually effectively kill this mutant without altering the source code.

# Report all the statistics and the mutation score for each test class

<img width="752" alt="Screenshot 2023-03-15 at 2 31 27 PM" src="https://user-images.githubusercontent.com/65151396/225435275-f80a3627-ad06-4c71-ba9b-f857cbb87679.png">
<img width="686" alt="Screenshot 2023-03-17 at 8 33 10 PM" src="https://user-images.githubusercontent.com/65151396/226078563-362698ed-b4b9-47f3-98a1-9173951d2ce9.png">

# Analysis drawn on the effectiveness of each of the test classes

After careful analysis of the mutation score and test coverage, the DataUtilitiesTest class was effective at catching defects. Before performing mutation tests and using our test suite from assignment #3, we have 60% mutation coverage. After performing extensive mutation testing on the test suite, we were able to achieve <b>99%</b>. One thing to keep in mind is that we did not test every method since we worked on improving the methods from the previous assignment.

Additionally, after beginning our analysis of Range class mutation score as well as test coverage, we saw that our class was fairly efficient on catching defects that were presented in the previous assignment as well as the mutants that were made during this assignment. Coming from the previous assignment we were at a 70% Line coverage with a 56% mutation score, after going through and fixing our test methods to kill the mutants that we found as well as add a few new tests we were able to increase our scores to 90% line coverage and <br>66%</br> mutation score.

# A discussion on the effect of equivalent mutants on mutation score accuracy

As we learned in class as well as through research that our group did on our own time. During mutation there can exist mutants that might be syntactically different however, they are semantically the same. This means that although the syntax has changed the program still performs in the exact same manner as the original program did. This means that we cannot kill these equivalent mutants that appear as they are operating in the exact same way that the original system did and as such the mutation score accuracy can appear lower than it should be. This is due to the reason that these equivalent mutants still count in the mutation score that appears; however, as we are unable to kill them, they are simply increasing the ratio of killed to total mutants thus skewing the percentage to be lower.

# A discussion of what could have been done to improve the mutation score of the test suites

For the DataUtilities test suite, we already had a 60% mutation score so our tests covered a large amount of mutants. However, one thing we noticed is that we didn’t check for null values and mutants for exceptions being thrown. For example, a lot of methods have a function that checks if a parameter is null. When that function was removed, the mutant survived since we did not check exceptions for null values. After checking for exceptions, it increased our mutation score by almost ~8%.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing is a crucial part of the test-case-design and test-evaluation process. By purposely injecting faults into the system. Some advantages of mutation testing is that it measures the quality of test cases, compared with other methods of testing, mutation testing provides the tester with a clear target which is the number of mutants to kill and since there is a greater focus on inspecting the source code, it forces the programmer to think of test data that will expose certain kinds of faults. Some disadvantages associated with mutation testing is that there could be a large amount of equivalent mutants that are undetected by the system, too many mutants could also require a lot of time. The classes we were analyzing weren’t that large and it still took a considerable amount of time. With a much larger system, trying to cover every mutant could be demanding in both time and resources. 

# Explain your SELENUIM test case design process

We chose our test cases based on what we think the most likely actions a user would make while browsing the website. The four functions that were chosen were Register, Login, Add/Remove from cart, Search by name, Search by category, Filter and Sort items, Add to wishlist and view cart. For each function we tested multiple inputs to see how the system behaves.

# Explain the use of assertions and checkpoints

By utilizing assertions and checkpoints, this allows you to verify data consistency and observe the state of the system at a certain point in time. This is especially useful in the case that there is a defect.  Assertions also help verify that the correct data is entered/passed when interacting with the UI by comparing the actual value to an expected value. With multiple breakpoints, this allows you to step through the code and test which allows you to carefully examine the state of the system and pinpoint any bugs.

# how did you test each functionaity with different test data

When testing the different functionalities of the website, we did so by using a wide range of input values as well as testing invalid values to ensure that they were caught. For example, when testing the Register feature, the user is prompted to enter their name, email, password as well as verify their password. To thoroughly test this feature, we had a test case where all valid inputs were provided, then another test case to see if the form would catch an invalid email, then another with a password that does not pass the strength requirement. This would ensure our tests covered a wide range of data.

# Discuss advantages and disadvantages of Selenium vs. Sikulix

One clear advantage Selenium has over Sikulix is its ease of use. Since Selenium is available on a variety of browsers, it makes the IDE accessible regardless of the operating system you are using. Along with that, the user interface is friendly and easy to walk through web apps as well as verifying the state of the app. However, a disadvantage that Selenium has is that it is limited to web apps. This is where Sikulix shines because it is able to work on both web apps as well as window applications. Although versatile, a disadvantage of Sikulix is that it analyzes screenshots so because of that, it might select the wrong screenshot. Along with that, it can be overwhelming managing a large amount of screenshots, especially if an application has many screens.

# How the team work/effort was divided and managed

We decided to split into groups of two where one group would increase the mutation coverage of the DataUtilities class while the other group increased the mutation coverage of the Range class. For the GUI testing, we all chose a function of the chosen website and created multiple inputs test cases for them.

# Difficulties encountered, challenges overcome, and lessons learned

Some of the difficulties that we encountered along the way were simply getting used to mutation testing. Compared to the previous testing methods that we learnt that were quite straightforward and simple, mutation testing was different for us and took us a small learning curve to fully understand before being able to increase our initial scores by the ~10% goal. We had minor difficulties as well setting up Pitclipse, however the major challenge was simply looking at the mutants that were created and effectively learning how to kill them in the end. For example, initially we were confused on whether the mutants were local variables that would be incremented and decremented; however, at the end of the lab we realized that we simply had to deal with boundary values. The lessons that we learned through this lab was simply to take everything slowly and make sure to understand the problem(in this case the mutant) and then attempt to fix it step-by-step rather than try to create an entirely new test case, and this method proved to be the most efficient for our group.

# Comments/feedback on the lab itself

The lab was structured well and had clear instructions.
